<!doctype html>
<html class="no-js" lang="en" data-content_root="">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><link rel="index" title="Index" href="../../../genindex.html" /><link rel="search" title="Search" href="../../../search.html" />

    <!-- Generated with Sphinx 6.2.1 and Furo 2023.09.10 -->
        <title>pyml.neural_network.nn - pyml 0.0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo.css?digest=369552022d0b975c8e74270ce6eabe0fb7978f24" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../../index.html"><div class="brand">pyml 0.0.1 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon no-toc" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../../index.html">
  
  
  <span class="sidebar-brand-text">pyml 0.0.1 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../index.html">Home page</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../_autosummary/pyml.html">API reference</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of API reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../_autosummary/pyml.exceptions.html">pyml.exceptions</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of pyml.exceptions</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../_autosummary/pyml.exceptions.excpetions.html">pyml.exceptions.excpetions</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of pyml.exceptions.excpetions</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/pyml.exceptions.excpetions.HyperparametersNotSpecified.html">pyml.exceptions.excpetions.HyperparametersNotSpecified</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/pyml.exceptions.excpetions.OutsideSpecifiedRange.html">pyml.exceptions.excpetions.OutsideSpecifiedRange</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/pyml.exceptions.excpetions.ShapeError.html">pyml.exceptions.excpetions.ShapeError</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neighbors.html">pyml.neighbors</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of pyml.neighbors</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neighbors.knn.html">pyml.neighbors.knn</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of pyml.neighbors.knn</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/pyml.neighbors.knn.kNNClassifier.html">pyml.neighbors.knn.kNNClassifier</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/pyml.neighbors.knn.UnknownMetric.html">pyml.neighbors.knn.UnknownMetric</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.html">pyml.neural_network</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of pyml.neural_network</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.layer.html">pyml.neural_network.layer</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of pyml.neural_network.layer</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.layer.activation.html">pyml.neural_network.layer.activation</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of pyml.neural_network.layer.activation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l5 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.layer.activation.linear.html">pyml.neural_network.layer.activation.linear</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of pyml.neural_network.layer.activation.linear</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l6"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.layer.activation.linear.Linear.html">pyml.neural_network.layer.activation.linear.Linear</a></li>
</ul>
</li>
<li class="toctree-l5 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.layer.activation.relu.html">pyml.neural_network.layer.activation.relu</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of pyml.neural_network.layer.activation.relu</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l6"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.layer.activation.relu.ReLU.html">pyml.neural_network.layer.activation.relu.ReLU</a></li>
</ul>
</li>
<li class="toctree-l5 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.layer.activation.sigmoid.html">pyml.neural_network.layer.activation.sigmoid</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of pyml.neural_network.layer.activation.sigmoid</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l6"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.layer.activation.sigmoid.Sigmoid.html">pyml.neural_network.layer.activation.sigmoid.Sigmoid</a></li>
</ul>
</li>
<li class="toctree-l5 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.layer.activation.softmax.html">pyml.neural_network.layer.activation.softmax</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of pyml.neural_network.layer.activation.softmax</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l6"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.layer.activation.softmax.Softmax.html">pyml.neural_network.layer.activation.softmax.Softmax</a></li>
</ul>
</li>
<li class="toctree-l5 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.layer.activation.tanh.html">pyml.neural_network.layer.activation.tanh</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of pyml.neural_network.layer.activation.tanh</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l6"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.layer.activation.tanh.Tanh.html">pyml.neural_network.layer.activation.tanh.Tanh</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l4 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.layer.transformation.html">pyml.neural_network.layer.transformation</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of pyml.neural_network.layer.transformation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l5 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.layer.transformation.convolutional.html">pyml.neural_network.layer.transformation.convolutional</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle navigation of pyml.neural_network.layer.transformation.convolutional</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l6"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.layer.transformation.convolutional.Convolutional.html">pyml.neural_network.layer.transformation.convolutional.Convolutional</a></li>
</ul>
</li>
<li class="toctree-l5 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.layer.transformation.dense.html">pyml.neural_network.layer.transformation.dense</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle navigation of pyml.neural_network.layer.transformation.dense</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l6"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.layer.transformation.dense.Dense.html">pyml.neural_network.layer.transformation.dense.Dense</a></li>
</ul>
</li>
<li class="toctree-l5 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.layer.transformation.dropout.html">pyml.neural_network.layer.transformation.dropout</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle navigation of pyml.neural_network.layer.transformation.dropout</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l6"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.layer.transformation.dropout.Dropout.html">pyml.neural_network.layer.transformation.dropout.Dropout</a></li>
</ul>
</li>
<li class="toctree-l5 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.layer.transformation.input.html">pyml.neural_network.layer.transformation.input</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle navigation of pyml.neural_network.layer.transformation.input</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l6"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.layer.transformation.input.Input.html">pyml.neural_network.layer.transformation.input.Input</a></li>
</ul>
</li>
<li class="toctree-l5 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.layer.transformation.reshape.html">pyml.neural_network.layer.transformation.reshape</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle navigation of pyml.neural_network.layer.transformation.reshape</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l6"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.layer.transformation.reshape.Flatten.html">pyml.neural_network.layer.transformation.reshape.Flatten</a></li>
<li class="toctree-l6"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.layer.transformation.reshape.Reshape.html">pyml.neural_network.layer.transformation.reshape.Reshape</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.loss.html">pyml.neural_network.loss</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><div class="visually-hidden">Toggle navigation of pyml.neural_network.loss</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.loss.binary_cross_entropy.html">pyml.neural_network.loss.binary_cross_entropy</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><div class="visually-hidden">Toggle navigation of pyml.neural_network.loss.binary_cross_entropy</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.loss.binary_cross_entropy.BinaryCrossentropy.html">pyml.neural_network.loss.binary_cross_entropy.BinaryCrossentropy</a></li>
</ul>
</li>
<li class="toctree-l4 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.loss.categorical_cross_entropy.html">pyml.neural_network.loss.categorical_cross_entropy</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><div class="visually-hidden">Toggle navigation of pyml.neural_network.loss.categorical_cross_entropy</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.loss.categorical_cross_entropy.CategoricalCrossentropy.html">pyml.neural_network.loss.categorical_cross_entropy.CategoricalCrossentropy</a></li>
</ul>
</li>
<li class="toctree-l4 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.loss.mean_absolute_error.html">pyml.neural_network.loss.mean_absolute_error</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" role="switch" type="checkbox"/><label for="toctree-checkbox-23"><div class="visually-hidden">Toggle navigation of pyml.neural_network.loss.mean_absolute_error</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.loss.mean_absolute_error.MeanAbsoluteError.html">pyml.neural_network.loss.mean_absolute_error.MeanAbsoluteError</a></li>
</ul>
</li>
<li class="toctree-l4 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.loss.mean_squarred_error.html">pyml.neural_network.loss.mean_squarred_error</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" role="switch" type="checkbox"/><label for="toctree-checkbox-24"><div class="visually-hidden">Toggle navigation of pyml.neural_network.loss.mean_squarred_error</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.loss.mean_squarred_error.MeanSquaredError.html">pyml.neural_network.loss.mean_squarred_error.MeanSquaredError</a></li>
</ul>
</li>
<li class="toctree-l4 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.loss.softmax_loss_categorical_cross_entropy.html">pyml.neural_network.loss.softmax_loss_categorical_cross_entropy</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" role="switch" type="checkbox"/><label for="toctree-checkbox-25"><div class="visually-hidden">Toggle navigation of pyml.neural_network.loss.softmax_loss_categorical_cross_entropy</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.loss.softmax_loss_categorical_cross_entropy.Softmax_CategoricalCrossentropy.html">pyml.neural_network.loss.softmax_loss_categorical_cross_entropy.Softmax_CategoricalCrossentropy</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.nn.html">pyml.neural_network.nn</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" role="switch" type="checkbox"/><label for="toctree-checkbox-26"><div class="visually-hidden">Toggle navigation of pyml.neural_network.nn</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.nn.NN.html">pyml.neural_network.nn.NN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.nn.InconsistentLayerSizes.html">pyml.neural_network.nn.InconsistentLayerSizes</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.optimizer.html">pyml.neural_network.optimizer</a><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" role="switch" type="checkbox"/><label for="toctree-checkbox-27"><div class="visually-hidden">Toggle navigation of pyml.neural_network.optimizer</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.optimizer.adagrad.html">pyml.neural_network.optimizer.adagrad</a><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" role="switch" type="checkbox"/><label for="toctree-checkbox-28"><div class="visually-hidden">Toggle navigation of pyml.neural_network.optimizer.adagrad</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.optimizer.adagrad.Adagrad.html">pyml.neural_network.optimizer.adagrad.Adagrad</a></li>
</ul>
</li>
<li class="toctree-l4 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.optimizer.adam.html">pyml.neural_network.optimizer.adam</a><input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" role="switch" type="checkbox"/><label for="toctree-checkbox-29"><div class="visually-hidden">Toggle navigation of pyml.neural_network.optimizer.adam</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.optimizer.adam.Adam.html">pyml.neural_network.optimizer.adam.Adam</a></li>
</ul>
</li>
<li class="toctree-l4 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.optimizer.rmsprop.html">pyml.neural_network.optimizer.rmsprop</a><input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" role="switch" type="checkbox"/><label for="toctree-checkbox-30"><div class="visually-hidden">Toggle navigation of pyml.neural_network.optimizer.rmsprop</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.optimizer.rmsprop.RMSProp.html">pyml.neural_network.optimizer.rmsprop.RMSProp</a></li>
</ul>
</li>
<li class="toctree-l4 has-children"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.optimizer.sgd.html">pyml.neural_network.optimizer.sgd</a><input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" role="switch" type="checkbox"/><label for="toctree-checkbox-31"><div class="visually-hidden">Toggle navigation of pyml.neural_network.optimizer.sgd</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../_autosummary/pyml.neural_network.optimizer.sgd.SGD.html">pyml.neural_network.optimizer.sgd.SGD</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../_autosummary/pyml.utils.html">pyml.utils</a><input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" role="switch" type="checkbox"/><label for="toctree-checkbox-32"><div class="visually-hidden">Toggle navigation of pyml.utils</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../_autosummary/pyml.utils.accuracy.html">pyml.utils.accuracy</a><input class="toctree-checkbox" id="toctree-checkbox-33" name="toctree-checkbox-33" role="switch" type="checkbox"/><label for="toctree-checkbox-33"><div class="visually-hidden">Toggle navigation of pyml.utils.accuracy</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/pyml.utils.accuracy.BinaryClassAccuracy.html">pyml.utils.accuracy.BinaryClassAccuracy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/pyml.utils.accuracy.MultiClassAccuracy.html">pyml.utils.accuracy.MultiClassAccuracy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/pyml.utils.accuracy.RegressionAccuracy.html">pyml.utils.accuracy.RegressionAccuracy</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../_autosummary/pyml.utils.metrics.html">pyml.utils.metrics</a><input class="toctree-checkbox" id="toctree-checkbox-34" name="toctree-checkbox-34" role="switch" type="checkbox"/><label for="toctree-checkbox-34"><div class="visually-hidden">Toggle navigation of pyml.utils.metrics</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/pyml.utils.metrics.euclidean_distance.html">pyml.utils.metrics.euclidean_distance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../_autosummary/pyml.utils.metrics.manhatten_distance.html">pyml.utils.metrics.manhatten_distance</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../tutorials.html">Examples and tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-35" name="toctree-checkbox-35" role="switch" type="checkbox"/><label for="toctree-checkbox-35"><div class="visually-hidden">Toggle navigation of Examples and tutorials</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../notebooks/kNN.html">Tutorial: kNN</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../notebooks/nn_classification.html">Tutorial: Neural Networks for classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../notebooks/nn_image_classification_without_convolution.html">Tutorial: Neural Networks for Image Classification without Convolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../notebooks/nn_image_classification_with_convolution.html">Tutorial: Neural Networks for Image Classification with Convolution</a></li>
</ul>
</li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon no-toc" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <h1>Source code for pyml.neural_network.nn</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Neural network</span>

<span class="sd">This module provides a simple implementation of a neural network.&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="c1"># Import of parent classes</span>
<span class="kn">from</span> <span class="nn">pyml.neural_network.layer</span> <span class="kn">import</span> <span class="n">_Layer</span>
<span class="kn">from</span> <span class="nn">pyml.neural_network.loss</span> <span class="kn">import</span> <span class="n">_Loss</span>
<span class="kn">from</span> <span class="nn">pyml.neural_network.optimizer</span> <span class="kn">import</span> <span class="n">_Optimizer</span>
<span class="kn">from</span> <span class="nn">pyml.neural_network.layer.activation</span> <span class="kn">import</span> <span class="n">_Activation</span>
<span class="kn">from</span> <span class="nn">pyml.neural_network.layer.transformation</span> <span class="kn">import</span> <span class="n">_Transformation</span><span class="p">,</span> <span class="n">_TrainableTransformation</span><span class="p">,</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Dropout</span>
<span class="kn">from</span> <span class="nn">pyml.utils.accuracy</span> <span class="kn">import</span> <span class="n">_Accuracy</span>

<span class="c1"># Import layers, losses, optimizers</span>
<span class="kn">from</span> <span class="nn">pyml.neural_network.layer.activation</span> <span class="kn">import</span> <span class="n">Softmax</span>
<span class="kn">from</span> <span class="nn">pyml.neural_network.loss</span> <span class="kn">import</span> <span class="n">CategoricalCrossentropy</span><span class="p">,</span> <span class="n">Softmax_CategoricalCrossentropy</span>

<span class="c1"># Exceptions</span>
<span class="kn">from</span> <span class="nn">pyml.exceptions</span> <span class="kn">import</span> <span class="n">HyperparametersNotSpecified</span>

<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<div class="viewcode-block" id="InconsistentLayerSizes"><a class="viewcode-back" href="../../../_autosummary/pyml.neural_network.nn.InconsistentLayerSizes.html#pyml.neural_network.nn.InconsistentLayerSizes">[docs]</a><span class="k">class</span> <span class="nc">InconsistentLayerSizes</span><span class="p">(</span><span class="ne">Exception</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Exception raised when neurons of two consecutive layers do not match.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    output_size_previous_layer : int</span>
<span class="sd">        Ouput neurons from previous layers</span>
<span class="sd">    input_size_current_layer : int</span>
<span class="sd">        Input size of current layer</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from pyml.nn import NN</span>
<span class="sd">    &gt;&gt;&gt; model = NN()</span>
<span class="sd">    &gt;&gt;&gt; model.add(Dense(4, 16))</span>
<span class="sd">    &gt;&gt;&gt; model.add(Activation_ReLU())</span>
<span class="sd">    &gt;&gt;&gt; model.add(Layer_Dense(20, 10))</span>
<span class="sd">    InconsistentLayerSizes: The output size of the previous layer: 16 and the input size of the current layer: 17 do not match.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_size_previous_layer</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">input_size_current_layer</span><span class="p">:</span><span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">message</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;The output size of the previous layer: </span><span class="si">{</span><span class="n">output_size_previous_layer</span><span class="si">}</span><span class="s1"> &#39;</span> <span class="o">+</span> \
            <span class="sa">f</span><span class="s1">&#39;and the input size of the current layer: </span><span class="si">{</span><span class="n">input_size_current_layer</span><span class="si">}</span><span class="s1"> do not match.&#39;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">message</span><span class="p">)</span></div>

<div class="viewcode-block" id="NN"><a class="viewcode-back" href="../../../_autosummary/pyml.neural_network.nn.NN.html#pyml.neural_network.nn.NN">[docs]</a><span class="k">class</span> <span class="nc">NN</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Neural network class for regression &amp; classification</span>

<span class="sd">    This class provides functionality for building, training, and evaluating neural networks.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    layers : list[_Layer]</span>
<span class="sd">        A list of layers in the neural network.</span>
<span class="sd">    trainable_layers : list[_TrainableTransformation]</span>
<span class="sd">        A list of trainable layers in the neural network.</span>
<span class="sd">    loss : _Loss</span>
<span class="sd">        The loss function used for training the network.</span>
<span class="sd">    optimizer : _Optimizer</span>
<span class="sd">        The optimizer used for updating network parameters during training.</span>
<span class="sd">    accuracy : _Accuracy</span>
<span class="sd">        The accuracy metric used for evaluating the network&#39;s performance.</span>
<span class="sd">    finished_build : bool</span>
<span class="sd">        Indicates whether the neural network has been built.</span>

<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from pyml.nn import NN</span>
<span class="sd">    &gt;&gt;&gt; network = NN()</span>
<span class="sd">    &gt;&gt;&gt; network.add_layer(Dense(4, 512))</span>
<span class="sd">    &gt;&gt;&gt; network.add_layer(ReLU())</span>
<span class="sd">    &gt;&gt;&gt; network.add_layer(Dropout(0.2))</span>
<span class="sd">    &gt;&gt;&gt; network.add_layer(Dense(512, NUM_CLASSES))</span>
<span class="sd">    &gt;&gt;&gt; network.add_layer(Softmax())</span>

<span class="sd">    &gt;&gt;&gt; model.set_loss(CategoricalCrossentropy())</span>
<span class="sd">    &gt;&gt;&gt; model.set_optimizer(Adam(learning_rate=0.005, decay=5e-5))</span>
<span class="sd">    &gt;&gt;&gt; model.set_accuracy(MultiClassAccuracy())</span>

<span class="sd">    &gt;&gt;&gt; model.build()</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainable_layers</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Hyperparameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">accuracy</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">finished_build</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">softmax_classifier_output</span> <span class="o">=</span> <span class="kc">None</span>


    <span class="k">def</span> <span class="nf">_get_last_connected_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">_Transformation</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">layer</span>
        
<div class="viewcode-block" id="NN.add_layer"><a class="viewcode-back" href="../../../_autosummary/pyml.neural_network.nn.NN.html#pyml.neural_network.nn.NN.add_layer">[docs]</a>    <span class="k">def</span> <span class="nf">add_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer</span><span class="p">:</span> <span class="n">_Layer</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Adds layer to the model</span>

<span class="sd">        Iteratively adds layers to the model.</span>
<span class="sd">        These layers can be e.g. conventional dense layers or activation functions.</span>
<span class="sd">        Be aware: the order of appending the layers is crucial and matters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        layer : _Layer</span>
<span class="sd">            The layer to be added to the network.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        InconsistentLayerSizes</span>
<span class="sd">            Raised when adding a layer where input size does not match the output size of the previous layer</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; from pyml.nn import NN</span>
<span class="sd">        &gt;&gt;&gt; model = NN()</span>
<span class="sd">        &gt;&gt;&gt; model.add(Dense(4, 16))</span>
<span class="sd">        &gt;&gt;&gt; model.add(ReLU())</span>
<span class="sd">        &gt;&gt;&gt; model.add(Dense(16, 32))</span>
<span class="sd">        &gt;&gt;&gt; model.add(ReLU())</span>
<span class="sd">        &gt;&gt;&gt; ...</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
        <span class="k">return</span>

        <span class="c1"># TODO: Update to handle convolutions and reshape layer</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">_Activation</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
            <span class="k">return</span>
        
        <span class="n">last_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_last_connected_layer</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">last_layer</span><span class="o">.</span><span class="n">output_size</span> <span class="o">!=</span> <span class="n">layer</span><span class="o">.</span><span class="n">input_size</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">InconsistentLayerSizes</span><span class="p">(</span><span class="n">last_layer</span><span class="o">.</span><span class="n">output_size</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">input_size</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span></div>
    
<div class="viewcode-block" id="NN.set_loss"><a class="viewcode-back" href="../../../_autosummary/pyml.neural_network.nn.NN.html#pyml.neural_network.nn.NN.set_loss">[docs]</a>    <span class="k">def</span> <span class="nf">set_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span><span class="n">_Loss</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the loss function for the neural network.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        loss : _Loss</span>
<span class="sd">            The loss function to be used for training.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span></div>
    
<div class="viewcode-block" id="NN.set_optimizer"><a class="viewcode-back" href="../../../_autosummary/pyml.neural_network.nn.NN.html#pyml.neural_network.nn.NN.set_optimizer">[docs]</a>    <span class="k">def</span> <span class="nf">set_optimizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">:</span><span class="n">_Optimizer</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the optimizer for the neural network.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        optimizer : _Optimizer</span>
<span class="sd">            The optimizer to be used for updating parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span></div>
    
<div class="viewcode-block" id="NN.set_accuracy"><a class="viewcode-back" href="../../../_autosummary/pyml.neural_network.nn.NN.html#pyml.neural_network.nn.NN.set_accuracy">[docs]</a>    <span class="k">def</span> <span class="nf">set_accuracy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">:</span><span class="n">_Accuracy</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the accuracy metric for the neural network.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        accuracy : _Accuracy</span>
<span class="sd">            The accuracy metric to be used for evaluation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy</span></div>

<div class="viewcode-block" id="NN.check_hyperparameters"><a class="viewcode-back" href="../../../_autosummary/pyml.neural_network.nn.NN.html#pyml.neural_network.nn.NN.check_hyperparameters">[docs]</a>    <span class="k">def</span> <span class="nf">check_hyperparameters</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Check if essential hyperparameters are specified.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        HyperparametersNotSpecified</span>
<span class="sd">            If any of the essential hyperparameters is not specified.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">HyperparametersNotSpecified</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">HyperparametersNotSpecified</span><span class="p">(</span><span class="s1">&#39;optimizer&#39;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">accuracy</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">HyperparametersNotSpecified</span><span class="p">(</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="NN.build"><a class="viewcode-back" href="../../../_autosummary/pyml.neural_network.nn.NN.html#pyml.neural_network.nn.NN.build">[docs]</a>    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Build the neural network architecture.</span>

<span class="sd">        This method sets up the connections between layers and prepares the network for training.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Check that all hyperparameters are initialized</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">check_hyperparameters</span><span class="p">()</span>
        
        <span class="c1"># Set input layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span> <span class="o">=</span> <span class="n">Input</span><span class="p">()</span>

        <span class="c1"># Count the number of layers</span>
        <span class="n">layer_count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span>

        <span class="c1"># Set order of the layers and specifiy their direct neighbors</span>
        <span class="c1"># and retrieve all trainable layers</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">layer_count</span><span class="p">):</span>

            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_adjacent_layers</span><span class="p">(</span>
                    <span class="n">previous_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span><span class="p">,</span>
                    <span class="n">next_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">layer_count</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_adjacent_layers</span><span class="p">(</span>
                    <span class="n">previous_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                    <span class="n">next_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_adjacent_layers</span><span class="p">(</span>
                    <span class="n">previous_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                    <span class="n">next_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span>
                <span class="p">)</span>
                <span class="c1"># Final layer is not the loss</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>


            <span class="c1"># Retrieve the trainable layers</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">_TrainableTransformation</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">trainable_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

            
        <span class="c1"># Pass the trainable layers to the loss instance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">set_trainable_layers</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainable_layers</span><span class="p">)</span>

        <span class="c1"># Create a combined activation and loss function object with faster gradient calculation</span>
        <span class="c1"># if using Softmax output activation and Categorical Cross-Entropy loss function</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">Softmax</span><span class="p">)</span> <span class="ow">and</span> \
           <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">CategoricalCrossentropy</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">softmax_classifier_output</span> <span class="o">=</span> \
                <span class="n">Softmax_CategoricalCrossentropy</span><span class="p">()</span>


        <span class="bp">self</span><span class="o">.</span><span class="n">finished_build</span> <span class="o">=</span> <span class="kc">True</span></div>

<div class="viewcode-block" id="NN.print_summary"><a class="viewcode-back" href="../../../_autosummary/pyml.neural_network.nn.NN.html#pyml.neural_network.nn.NN.print_summary">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">print_summary</span><span class="p">(</span>
        <span class="n">context</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">accuracy</span><span class="p">:</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">loss</span><span class="p">:</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">data_loss</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">regularization_loss</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Print a summary of training or evaluation results.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        context : str</span>
<span class="sd">            Context for the summary (e.g., &#39;training&#39;, &#39;validation&#39;).</span>
<span class="sd">        accuracy : float</span>
<span class="sd">            The accuracy achieved during training or evaluation.</span>
<span class="sd">        loss : float</span>
<span class="sd">            The total loss achieved during training or evaluation.</span>
<span class="sd">        data_loss : float, optional</span>
<span class="sd">            The data loss component of the total loss, by default None.</span>
<span class="sd">        regularization_loss : float, optional</span>
<span class="sd">            The regularization loss component of the total loss, by default None.</span>
<span class="sd">        learning_rate : float, optional</span>
<span class="sd">            The learning rate used during training, by default None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="c1"># Set values to --- if not specified</span>
        <span class="n">data_loss</span> <span class="o">=</span> <span class="s1">&#39;- - -&#39;</span> <span class="k">if</span> <span class="n">data_loss</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">data_loss</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span>
        <span class="n">regularization_loss</span> <span class="o">=</span> <span class="s1">&#39;- - -&#39;</span> <span class="k">if</span> <span class="n">regularization_loss</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">regularization_loss</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span>
        <span class="n">learning_rate</span> <span class="o">=</span> <span class="s1">&#39;- - -&#39;</span> <span class="k">if</span> <span class="n">learning_rate</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">learning_rate</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span>

        <span class="nb">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">context</span><span class="si">}</span><span class="s1">, &#39;</span> <span class="o">+</span>
            <span class="sa">f</span><span class="s1">&#39;acc: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">, &#39;</span> <span class="o">+</span>
            <span class="sa">f</span><span class="s1">&#39;loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1"> (&#39;</span> <span class="o">+</span>
            <span class="sa">f</span><span class="s1">&#39;data_loss: </span><span class="si">{</span><span class="n">data_loss</span><span class="si">}</span><span class="s1">, &#39;</span> <span class="o">+</span>
            <span class="sa">f</span><span class="s1">&#39;reg_loss: </span><span class="si">{</span><span class="n">regularization_loss</span><span class="si">}</span><span class="s1">), &#39;</span> <span class="o">+</span>
            <span class="sa">f</span><span class="s1">&#39;lr: </span><span class="si">{</span><span class="n">learning_rate</span><span class="si">}</span><span class="s1">&#39;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="NN.train"><a class="viewcode-back" href="../../../_autosummary/pyml.neural_network.nn.NN.html#pyml.neural_network.nn.NN.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">y</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">epochs</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">validation_data</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">print_summary_every</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">save_file_path</span><span class="p">:</span><span class="nb">str</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Train the neural network.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------        </span>
<span class="sd">        &gt;&gt;&gt; X_train, y_train, X_test, y_test = ...  # Load training data</span>
<span class="sd">        &gt;&gt;&gt; network.train(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : numpy.ndarray</span>
<span class="sd">            The input training data.</span>
<span class="sd">        y : numpy.ndarray</span>
<span class="sd">            The target training data.</span>
<span class="sd">        epochs : int, optional</span>
<span class="sd">            The number of training epochs, by default 1.</span>
<span class="sd">        batch_size : int, optional</span>
<span class="sd">            The batch size for training, by default None.</span>
<span class="sd">        validation_data : numpy.ndarray, optional</span>
<span class="sd">            Validation data for evaluation during training.</span>
<span class="sd">            Should include data (X) and their labels (y), by default None.</span>
<span class="sd">        verbose : int, optional</span>
<span class="sd">            Verbosity level (0: no prints, 1: epoch summary, 2: detailed prints), by default 0.</span>
<span class="sd">        print_summary_every : int, optional</span>
<span class="sd">            Print summary every &#39;print_summary_every&#39; steps, by default 1.</span>
<span class="sd">        save_file_path : str, optional</span>
<span class="sd">            Path to save the model parameters after training, by default None.</span>
<span class="sd">            TODO: NOT IMPLEMENTED YET</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># VERBOSE DESCRIPTION------------------------|</span>
        <span class="c1"># VERBOSE == 0: no prints at all             |</span>
        <span class="c1"># VERBOSE == 1: print only epoch summary     |</span>
        <span class="c1"># VERBOSE == 2: print also after major steps |</span>
        <span class="c1"># -------------------------------------------|</span>
    

        <span class="c1"># Check if model has already been build, if not build now</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">finished_build</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="o">&gt;</span><span class="mi">1</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;training: model had to been build&#39;</span><span class="p">)</span>

        <span class="c1"># Check that all hyperparameters are initialized</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">check_hyperparameters</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="o">&gt;</span><span class="mi">1</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;training: all hyperparameters have been initialized&#39;</span><span class="p">)</span>

        <span class="c1"># Initialize accuracy instance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">accuracy</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="o">&gt;</span><span class="mi">1</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;training: accuracy instance has been initialized&#39;</span><span class="p">)</span>

        <span class="c1"># Compute step size</span>
        <span class="c1"># Training step size describes how many many batches will be forwarded during each epoch</span>
        <span class="n">training_step_size</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># training step size = ⌊ count of tranings data / batch size ⌋</span>
            <span class="n">training_step_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span>
            <span class="c1"># Add single training step if some trainings data will remain left over</span>
            <span class="k">if</span> <span class="n">training_step_size</span> <span class="o">*</span> <span class="n">batch_size</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
                <span class="n">training_step_size</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="o">&gt;</span><span class="mi">1</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;training: training steps size has been computed -- training step size: </span><span class="si">{</span><span class="n">training_step_size</span><span class="si">}</span><span class="s1">, batch size: </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="c1"># Start training</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="o">&gt;</span><span class="mi">1</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;training: start training&#39;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            
            <span class="c1"># Print current epoch</span>
            <span class="k">if</span> <span class="n">verbose</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;training: Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

            <span class="c1"># Reset loss and accuracy</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">accuracy</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

            <span class="k">for</span> <span class="n">training_step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">training_step_size</span><span class="p">):</span>

                <span class="c1"># Print current training step</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="o">&gt;</span><span class="mi">1</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;training: Training step: </span><span class="si">{</span><span class="n">training_step</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">training_step_size</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

                <span class="c1"># Compute the batch</span>
                <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">X_batch</span> <span class="o">=</span> <span class="n">X</span>
                    <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">lower_limit</span> <span class="o">=</span> <span class="n">training_step</span><span class="o">*</span><span class="n">batch_size</span>
                    <span class="n">upper_limit</span> <span class="o">=</span> <span class="p">(</span><span class="n">training_step</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">batch_size</span>
                    <span class="n">X_batch</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">lower_limit</span><span class="p">:</span><span class="n">upper_limit</span><span class="p">]</span>
                    <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">lower_limit</span><span class="p">:</span><span class="n">upper_limit</span><span class="p">]</span>
                
                <span class="c1"># Compute forward pass</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="o">&gt;</span><span class="mi">1</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;training: Compute forward pass&#39;</span><span class="p">)</span>
                <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

                <span class="c1"># Compute loss</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="o">&gt;</span><span class="mi">1</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;training: Compute loss&#39;</span><span class="p">)</span>
                <span class="n">data_loss</span><span class="p">,</span> <span class="n">regularization_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">calculate</span><span class="p">(</span>
                    <span class="n">output</span><span class="p">,</span> 
                    <span class="n">y_batch</span><span class="p">,</span> 
                    <span class="n">include_regularization</span><span class="o">=</span><span class="kc">True</span>
                <span class="p">)</span>
                <span class="c1"># Combine loss of data loss and regularization loss</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">data_loss</span> <span class="o">+</span> <span class="n">regularization_loss</span>

                <span class="c1"># Compute backward</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="o">&gt;</span><span class="mi">1</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;training: Compute backward&#39;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>

                <span class="c1"># Update parameter weights</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="o">&gt;</span><span class="mi">1</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;training: Update parameters&#39;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">pre_update_parameters</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_layers</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">update_parameters</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">post_update_parameters</span><span class="p">()</span>

                <span class="c1"># Calculate accuracy</span>
                <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="o">.</span><span class="n">predictions</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
                <span class="n">accuracy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">accuracy</span><span class="o">.</span><span class="n">calculate</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>

                <span class="c1"># Print step size summary</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="o">&gt;</span><span class="mi">1</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="n">training_step</span> <span class="o">%</span> <span class="n">print_summary_every</span> <span class="ow">or</span> <span class="n">training_step</span> <span class="o">==</span> <span class="n">training_step_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
                    <span class="n">NN</span><span class="o">.</span><span class="n">print_summary</span><span class="p">(</span>
                        <span class="s1">&#39;training&#39;</span><span class="p">,</span>
                        <span class="n">accuracy</span><span class="p">,</span>
                        <span class="n">loss</span><span class="p">,</span>
                        <span class="n">data_loss</span><span class="p">,</span>
                        <span class="n">regularization_loss</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">current_learning_rate</span>
                    <span class="p">)</span> 

            <span class="c1"># Print epoch summary</span>
            <span class="n">epoch_data_loss</span><span class="p">,</span> <span class="n">epoch_regularization_loss</span> <span class="o">=</span> \
                <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">calculate_accumulated</span><span class="p">(</span>
                    <span class="n">include_regularization</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">epoch_loss</span> <span class="o">=</span> <span class="n">epoch_data_loss</span> <span class="o">+</span> <span class="n">epoch_regularization_loss</span>
            <span class="n">epoch_accuracy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">accuracy</span><span class="o">.</span><span class="n">calculate_accumulated</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">NN</span><span class="o">.</span><span class="n">print_summary</span><span class="p">(</span>
                    <span class="s1">&#39;epoch&#39;</span><span class="p">,</span>
                    <span class="n">epoch_accuracy</span><span class="p">,</span>
                    <span class="n">epoch_loss</span><span class="p">,</span>
                    <span class="n">epoch_data_loss</span><span class="p">,</span>
                    <span class="n">epoch_regularization_loss</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">current_learning_rate</span>
                <span class="p">)</span>

            <span class="c1"># Evaluate model on validaten data</span>
            <span class="k">if</span> <span class="n">validation_data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="o">*</span><span class="n">validation_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="o">&gt;</span><span class="mi">1</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;training: Training finished&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="NN._forward"><a class="viewcode-back" href="../../../_autosummary/pyml.neural_network.nn.NN.html#pyml.neural_network.nn.NN._forward">[docs]</a>    <span class="k">def</span> <span class="nf">_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer</span><span class="p">:</span><span class="n">_Layer</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">training</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform a forward pass through a layer.</span>

<span class="sd">        If the layer is a dropout layer, the training context (true or false is also passed).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        layer : _Layer</span>
<span class="sd">            The layer to perform the forward pass on.</span>
<span class="sd">        X : numpy.ndarray</span>
<span class="sd">            The input data.</span>
<span class="sd">        training : bool, optional</span>
<span class="sd">            Indicates if the network is in training mode, by default False.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">):</span>
            <span class="n">layer</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">training</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">layer</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></div>
                
<div class="viewcode-block" id="NN.forward"><a class="viewcode-back" href="../../../_autosummary/pyml.neural_network.nn.NN.html#pyml.neural_network.nn.NN.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">training</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform a forward pass through the entire neural network.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : numpy.ndarray</span>
<span class="sd">            The input data.</span>
<span class="sd">        training : bool, optional</span>
<span class="sd">            Indicates if the network is in training mode, by default False.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        numpy.ndarray</span>
<span class="sd">            The output of the network.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Forward data trough input layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_forward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">training</span><span class="p">)</span>

        <span class="c1"># Iterate through remaining layers</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_forward</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">previous_layer</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">training</span><span class="p">)</span>

        <span class="c1"># Return output of last layer</span>
        <span class="k">return</span> <span class="n">layer</span><span class="o">.</span><span class="n">output</span></div>

<div class="viewcode-block" id="NN.backward"><a class="viewcode-back" href="../../../_autosummary/pyml.neural_network.nn.NN.html#pyml.neural_network.nn.NN.backward">[docs]</a>    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform a backward pass through the neural network.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        output : numpy.ndarray</span>
<span class="sd">            The output of the network.</span>
<span class="sd">        y : numpy.ndarray</span>
<span class="sd">            The target data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Conduct backward pass if softmax classifier</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax_classifier_output</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">softmax_classifier_output</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        
            <span class="c1"># Skip backward step for last layer since we combined activation and loss</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">dinputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax_classifier_output</span><span class="o">.</span><span class="n">dinputs</span>

            <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
                <span class="n">layer</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">next_layer</span><span class="o">.</span><span class="n">dinputs</span><span class="p">)</span>
            
            <span class="c1"># Finish</span>
            <span class="k">return</span>
        
        <span class="c1"># Compute backward as usual</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
            <span class="n">layer</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">next_layer</span><span class="o">.</span><span class="n">dinputs</span><span class="p">)</span></div>

<div class="viewcode-block" id="NN.evaluate"><a class="viewcode-back" href="../../../_autosummary/pyml.neural_network.nn.NN.html#pyml.neural_network.nn.NN.evaluate">[docs]</a>    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_val</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y_val</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Evaluate the neural network on validation data.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X_val : numpy.ndarray</span>
<span class="sd">            The input validation data.</span>
<span class="sd">        y_val : numpy.ndarray</span>
<span class="sd">            The target validation data.</span>
<span class="sd">        batch_size : int, optional</span>
<span class="sd">            The batch size for evaluation, by default None.</span>
<span class="sd">        verbose : int, optional</span>
<span class="sd">            Verbosity level (0: no prints, 1: summary prints), by default 0.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Default step size</span>
        <span class="n">validation_step_size</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="c1"># Calculate number of batches</span>
        <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># training step size = ⌊ count of tranings data / batch size ⌋</span>
            <span class="n">training_step_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_val</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span>
            <span class="c1"># Add single training step if some trainings data will remain left over</span>
            <span class="k">if</span> <span class="n">training_step_size</span> <span class="o">*</span> <span class="n">batch_size</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_val</span><span class="p">):</span>
                <span class="n">training_step_size</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Reset loss and accuracy</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">accuracy</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>


        <span class="c1"># Iterate over steps</span>
        <span class="k">for</span> <span class="n">validation_step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">validation_step_size</span><span class="p">):</span>

            <span class="c1"># Compute the batch</span>
            <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">X_batch</span> <span class="o">=</span> <span class="n">X_val</span>
                <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_val</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">lower_limit</span> <span class="o">=</span> <span class="n">validation_step</span><span class="o">*</span><span class="n">batch_size</span>
                <span class="n">upper_limit</span> <span class="o">=</span> <span class="p">(</span><span class="n">validation_step</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">batch_size</span>
                <span class="n">X_batch</span> <span class="o">=</span> <span class="n">X_val</span><span class="p">[</span><span class="n">lower_limit</span><span class="p">:</span><span class="n">upper_limit</span><span class="p">]</span>
                <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_val</span><span class="p">[</span><span class="n">lower_limit</span><span class="p">:</span><span class="n">upper_limit</span><span class="p">]</span>

            <span class="c1"># Perform the forward pass</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="c1"># Calculate the loss</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">calculate</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>

            <span class="c1"># Get predictions and calculate an accuracy</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="o">.</span><span class="n">predictions</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">accuracy</span><span class="o">.</span><span class="n">calculate</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>

        <span class="c1"># Retrieve validation loss and accuracy</span>
        <span class="n">validation_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">calculate_accumulated</span><span class="p">()</span>
        <span class="n">validation_accuracy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">accuracy</span><span class="o">.</span><span class="n">calculate_accumulated</span><span class="p">()</span>

        <span class="c1"># Print a summary</span>
        <span class="k">if</span> <span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">NN</span><span class="o">.</span><span class="n">print_summary</span><span class="p">(</span>
            <span class="s1">&#39;validation&#39;</span><span class="p">,</span>
            <span class="n">validation_accuracy</span><span class="p">,</span>
            <span class="n">validation_loss</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="NN.predict"><a class="viewcode-back" href="../../../_autosummary/pyml.neural_network.nn.NN.html#pyml.neural_network.nn.NN.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate predictions using the trained neural network.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : np.ndarray</span>
<span class="sd">            The input data for which predictions are to be generated.</span>
<span class="sd">        batch_size : int, optional</span>
<span class="sd">            The batch size for prediction, by default None.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        numpy.ndarray</span>
<span class="sd">            The predictions generated by the network.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="c1"># Default value if batch size is not being set</span>
        <span class="n">prediction_step_size</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="c1"># Calculate number of batches</span>
        <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># training step size = ⌊ count of tranings data / batch size ⌋</span>
            <span class="n">prediction_step_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span>
            <span class="c1"># Add single training step if some trainings data will remain left over</span>
            <span class="k">if</span> <span class="n">prediction_step_size</span> <span class="o">*</span> <span class="n">batch_size</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
                <span class="n">prediction_step_size</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Model output</span>
        <span class="n">output</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">prediction_step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">prediction_step_size</span><span class="p">):</span>

            <span class="c1"># Get batch</span>
            <span class="k">if</span> <span class="n">batch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">batch_X</span> <span class="o">=</span> <span class="n">X</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">lower_limit</span> <span class="o">=</span> <span class="n">prediction_step</span><span class="o">*</span><span class="n">batch_size</span>
                <span class="n">upper_limit</span> <span class="o">=</span> <span class="p">(</span><span class="n">prediction_step</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">batch_size</span>
                <span class="n">batch_X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">lower_limit</span><span class="p">:</span><span class="n">upper_limit</span><span class="p">]</span>

        <span class="c1"># Perform the forward pass</span>
        <span class="n">batch_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">batch_X</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># Append batch prediction to the list of predictions</span>
        <span class="n">output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_output</span><span class="p">)</span>

        <span class="c1"># Stack output</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span></div>

<div class="viewcode-block" id="NN.get_model_parameters"><a class="viewcode-back" href="../../../_autosummary/pyml.neural_network.nn.NN.html#pyml.neural_network.nn.NN.get_model_parameters">[docs]</a>    <span class="k">def</span> <span class="nf">get_model_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;_summary_</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        list[numpy.ndarray]</span>
<span class="sd">            A list of numpy arrays containing the parameters of each trainable layer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">parameters</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_layers</span><span class="p">:</span>
            <span class="n">parameters</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">())</span>

        <span class="k">return</span> <span class="n">parameters</span></div>
    
<div class="viewcode-block" id="NN.set_model_parameters"><a class="viewcode-back" href="../../../_autosummary/pyml.neural_network.nn.NN.html#pyml.neural_network.nn.NN.set_model_parameters">[docs]</a>    <span class="k">def</span> <span class="nf">set_model_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parameters</span><span class="p">:</span><span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Set the parameters of the trainable layers in the model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        parameters : list[tuple[numpy.ndarray]]</span>
<span class="sd">            A list storing parameters for each trainable layer within a tuple.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">parameter</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_layers</span><span class="p">):</span>
            <span class="n">layer</span><span class="o">.</span><span class="n">set_parameters</span><span class="p">(</span><span class="o">*</span><span class="n">parameter</span><span class="p">)</span></div>

<div class="viewcode-block" id="NN.save_model_parameters"><a class="viewcode-back" href="../../../_autosummary/pyml.neural_network.nn.NN.html#pyml.neural_network.nn.NN.save_model_parameters">[docs]</a>    <span class="k">def</span> <span class="nf">save_model_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span><span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save the model parameters to a file.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        path : str</span>
<span class="sd">            The path to the file where the parameters will be saved.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">pickle</span><span class="o">.</span><span class="n">dumb</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_model_parameters</span><span class="p">())</span></div>

<div class="viewcode-block" id="NN.load_model_parameters"><a class="viewcode-back" href="../../../_autosummary/pyml.neural_network.nn.NN.html#pyml.neural_network.nn.NN.load_model_parameters">[docs]</a>    <span class="k">def</span> <span class="nf">load_model_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span><span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load and set the model parameters from a file.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        path : str</span>
<span class="sd">            The path to the file from which the parameters will be loaded.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_parameters</span><span class="p">(</span><span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">))</span></div>

<div class="viewcode-block" id="NN.save_model"><a class="viewcode-back" href="../../../_autosummary/pyml.neural_network.nn.NN.html#pyml.neural_network.nn.NN.save_model">[docs]</a>    <span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span><span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save the entire trained model to a file.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        path : str</span>
<span class="sd">            The path to the file where the model will be saved.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; network.save_model(&#39;trained_model.model&#39;)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># make copy of current model</span>
        <span class="n">model_copy</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="c1"># Reset loss and accuracy</span>
        <span class="n">model_copy</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="n">model_copy</span><span class="o">.</span><span class="n">accuracy</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

        <span class="c1"># Remove data related attributes in model</span>
        <span class="n">model_copy</span><span class="o">.</span><span class="n">input_layer</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;output&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">model_copy</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;dinputs&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model_copy</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="k">for</span> <span class="nb">property</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;inputs&#39;</span><span class="p">,</span> <span class="s1">&#39;output&#39;</span><span class="p">,</span> <span class="s1">&#39;dinputs&#39;</span><span class="p">,</span>
                             <span class="s1">&#39;dweights&#39;</span><span class="p">,</span> <span class="s1">&#39;dbiases&#39;</span><span class="p">]:</span>
                <span class="n">layer</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="nb">property</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="c1"># Save model</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">pickle</span><span class="o">.</span><span class="n">dumb</span><span class="p">(</span><span class="n">model_copy</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span></div>

<div class="viewcode-block" id="NN.load"><a class="viewcode-back" href="../../../_autosummary/pyml.neural_network.nn.NN.html#pyml.neural_network.nn.NN.load">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="n">path</span><span class="p">:</span><span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NN</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load a trained model from a file.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        path : str</span>
<span class="sd">            The path to the file from which the model will be loaded.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        NN</span>
<span class="sd">            The loaded trained model.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; loaded_model = NN.load(&#39;trained_model.model&#39;)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">model</span></div></div>
</pre></div>
        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023, Bastian Berle
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer no-toc">
      
      
      
    </aside>
  </div>
</div><script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/sphinx_highlight.js"></script>
    <script src="../../../_static/scripts/furo.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    </body>
</html>